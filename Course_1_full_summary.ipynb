{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 1 - Part 4 - Lesson 4 - Notebook.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5rc1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpant/TensorFlow/blob/main/Course_1_full_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNG9yKAlaL1v"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DNqVZRIaPrD"
      },
      "source": [
        "# GRADED FUNCTION: house_model\n",
        "# 1. you can give the np.array (from numpy) to tensorflow models.\n",
        "# This is coursera Course 1 Week 1 graded lab.\n",
        "def house_model(y_new):\n",
        "    xs = np.array([1,3,5,8,10],dtype=float)\n",
        "    ys = np.array([1,2,3,4.5,5.5],dtype=float)\n",
        "    model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
        "    model.compile(optimizer='sgd',loss='mean_squared_error')\n",
        "    model.fit(xs,ys,epochs=10)\n",
        "    model.summary()\n",
        "    return model.predict(y_new)[0]\n",
        "\n",
        "prediction = house_model([7.0])\n",
        "print(prediction)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9-BCmi15L93"
      },
      "source": [
        "# handling custom callback to stop training after certain accuracy 60% is reached.\n",
        "# notice you don't have to normalize the y_train or y_test. Notice below only\n",
        "# the x_train and x_test are normalized\n",
        "\n",
        "# 2 layer (512 nodes) NN get upto 94% in training set (after 20 epochs).\n",
        "# also the training accuracy increase very slowly in the later iterations.\n",
        "# this dataset is harder (to train) dataset compared to digit MNIST.\n",
        "# Using GPU from runtime speed up the training by 4X\n",
        "\n",
        "print(tf.__version__)\n",
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist # fashon MNIST\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVx358XdOtDJ"
      },
      "source": [
        "# print one image\n",
        "import matplotlib.pyplot as plt\n",
        "def printOneExample(image):\n",
        "  np.set_printoptions(linewidth=200)\n",
        "  plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbSQrTuUa9Vj"
      },
      "source": [
        "# Multilayer (deep) NN for digit MNIST.\n",
        "# Notice this two layer NN give >99% accuracy is train set and 98% in test set!\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist # digit MINIST\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "printOneExample(training_images[0])\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5 )\n",
        "\n",
        "print(\"\\n------Test accuracy-------\\n\")\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td_qod8MnrME"
      },
      "source": [
        "!git clone https://github.com/dpant/TensorFlow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l91EdLJPcZJy"
      },
      "source": [
        "# Handwriting recognization 1 layer. Training accuracy 99%. test accuracy 98%\n",
        "# Coursera: Tensorflow Course 1 Week 2 Lab.\n",
        "\n",
        "import tensorflow as tf\n",
        "from os import path, getcwd, chdir\n",
        "\n",
        "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
        "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
        "# and place it inside a local folder and edit the path to that location\n",
        "\n",
        "path = f\"{getcwd()}/TensorFlow/datasets/mnist.npz\"\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs={}):\n",
        "        print(\"\\n---\\n\",logs,\"\\n---\\n\")\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    callback = myCallback()    \n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
        "    print(x_train.shape)\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test/ 255.0\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(x_train,y_train,epochs=10,callbacks=[callback]\n",
        "    )\n",
        "    model.evaluate(x_test,y_test)\n",
        "    # model fitting\n",
        "    return history.epoch, history.history['accuracy'][-1]\n",
        "\n",
        "train_mnist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyYbLHYYkgzx"
      },
      "source": [
        "# Tensorflow Coursera Course 1 week 3\n",
        "# CNN for fashion MNIST.\n",
        "# CONV2-D--> MAX POOL --> CONV2-D--> MAX POOL --> DENSE(RELU) --> SOFTMAX\n",
        "# Notice this gives us ~99% accuracy in train set (after 20 epoch)\n",
        "# Just DNN was < 94%. This is sold 5% gain just by using convolution.\n",
        "# Training time with GPU is 4s per epoch. With CPU is 100s. 25x reduction using\n",
        "# GPU!!!. Conv nets are higly parallazable thus GPU training is very advantagous  \n",
        "# test accuracy 90%. We are overfitting!!\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=50)\n",
        "test_loss = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVMAxgj61SvA"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from os import path, getcwd, chdir\n",
        "path = f\"{getcwd()}/TensorFlow/datasets/happy-or-sad.zip\"\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall(\"/tmp/h-or-s\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7CquOQyfWi1"
      },
      "source": [
        "# happy or sad face detection. Use ImageGenerator() to fech training images\n",
        "# accuracy approx 100% in training set.\n",
        "# GRADED FUNCTION: train_happy_sad_model\n",
        "def train_happy_sad_model():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    DESIRED_ACCURACY = 0.999\n",
        "\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self,epoch,logs={}):\n",
        "            print(\"\\n---\\n\",logs,\"\\n---\\n\")\n",
        "            if logs.get('accuracy') is not None and logs.get('accuracy') > DESIRED_ACCURACY:\n",
        "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "\n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
        "    model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "        \n",
        "\n",
        "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
        "    # And a train_generator by calling train_datagen.flow_from_directory\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "    # Please use a target_size of 150 X 150.\n",
        "    train_generator =  train_datagen.flow_from_directory(\n",
        "        '/tmp/h-or-s/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 300x300\n",
        "        batch_size=10,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
        "\n",
        "    # This code block should call model.fit_generator and train for\n",
        "    # a number of epochs.\n",
        "    # model fitting\n",
        "    history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1)\n",
        "    return history.history['accuracy'][-1]\n",
        "# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\n",
        "train_happy_sad_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6Khcciy9vj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1SOUoN413_G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}